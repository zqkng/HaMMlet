{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aadc801-01ff-473e-aa0f-b0dbe0282cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "\n",
    "import numpy as np\n",
    "#from keras.models import Sequential, load_model\n",
    "#from keras.layers import Dense, LSTM, Lambda, Dropout\n",
    "#from keras.utils import to_categorical\n",
    "\n",
    "import hammlet\n",
    "import rnn\n",
    "import tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe76ce1e-05da-45eb-bf37-bf800ce47f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenizer.py\n",
    "## (default sonnet text data: 'data/shakespeare.txt' and 'data/spenser.txt)\n",
    "## ========================================================================\n",
    "\n",
    "data = tokenizer.load_data()\n",
    "sequences = tokenizer.sequence_full_sonnet(tokenizer.tokenize_lpunc, data)\n",
    "print(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31de907-2449-4890-ae5b-2610cc5a39b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rnn.py: pre-process and load RNN training sequences\n",
    "## ===================================================\n",
    "\n",
    "char_sequences, char2vec = rnn.load_rnn_data()\n",
    "print(f\"Total Number of (40-char) Sequences: {len(char_sequences)}\")\n",
    "print(f\"[char2vec]:\\n{char2vec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17073415-8383-43a9-9dcc-37ced117db42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## rnn.py: train/load/save model\n",
    "## =============================\n",
    "\n",
    "X, Y = rnn.generate_training_data(char_sequences, char2vec)\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "# RNN Model: \n",
    "#   - 3 LSTM layers of 600 units (each with 20% dropout)\n",
    "#   - 1 Dense layer with `softmax` activation\n",
    "#model = Sequential([\n",
    "#    LSTM(600, input_shape(X.shape[1], X.shape[2]), return_sequences=True),\n",
    "#    Dropout(0.2),\n",
    "#    LSTM(600, return_sequences=True),\n",
    "#    Dropout(0.2),\n",
    "#    LSTM(600),\n",
    "#    Dropout(0.2)\n",
    "#    Dense(len(char2vec), activation='softmax')\n",
    "#])\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model.fit(X, Y, batch_size=128, epochs=40)\n",
    "#model.summary()\n",
    "#model.save(\"LSTM-3L-600U-40E\")\n",
    "\n",
    "#model = rnn.train_rnn_model(X, Y, char2vec)\n",
    "model = rnn.load_rnn_model(\"LSTM-3L-600U-40E\")\n",
    "model.summary()\n",
    "\n",
    "temperatures = [1.5, 0.75, 0.25]\n",
    "models = []\n",
    "for temp in temperatures:\n",
    "    lambda_model = add_lambda_layer(model, char2vec, X, temp)\n",
    "    models.append(lambda_model)\n",
    "    lambda_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa04471a-4bf8-40e6-af2c-a5349f0781f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## hammlet.py: generate sonnets\n",
    "## ============================\n",
    "seed = \"My mistress' eyes are nothing like the sun,\"\n",
    "\n",
    "#for m in models:\n",
    "#    sonnet = rnn._gen_rnn_poem(m, char2vec, X, seed)\n",
    "#    print(sonnet)\n",
    "\n",
    "sonnet = rnn.generate_rnn_sonnet(model, seed, temperature=0.75)\n",
    "print(sonnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
